{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Let's load this data into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading ratings file\n",
    "# Ignore the timestamp column\n",
    "ratings = pd.read_csv('ratings.csv', encoding='latin-1', usecols=['user_id', 'movie_id', 'rating'])\n",
    "\n",
    "# Reading users file\n",
    "users = pd.read_csv('users.csv', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "\n",
    "# Reading movies file\n",
    "movies = pd.read_csv('movies.csv', encoding='latin-1', usecols=['movie_id', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Recommendation Model\n",
    "\n",
    "Computes similarity between movies based on movie genres. It will suggest movies that are most similar to a particular movie based on its genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Break up the big genre string into a string array\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "print(movies.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>['Animation', \"Children's\", 'Comedy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>['Adventure', \"Children's\", 'Fantasy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>['Comedy', 'Romance']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>['Comedy', 'Drama']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>['Comedy']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                               title  \\\n",
       "0         1                    Toy Story (1995)   \n",
       "1         2                      Jumanji (1995)   \n",
       "2         3             Grumpier Old Men (1995)   \n",
       "3         4            Waiting to Exhale (1995)   \n",
       "4         5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                   genres  \n",
       "0   ['Animation', \"Children's\", 'Comedy']  \n",
       "1  ['Adventure', \"Children's\", 'Fantasy']  \n",
       "2                   ['Comedy', 'Romance']  \n",
       "3                     ['Comedy', 'Drama']  \n",
       "4                              ['Comedy']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert genres to string value\n",
    "movies['genres'] = movies['genres'].fillna(\"\").astype('str')\n",
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 44)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(movies['genres'])\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<100x44 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 231 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.15337409,  0.12551391, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.15337409,  1.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.12551391,  0.        ,  1.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         0.        ,  0.25861841],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         1.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.25861841,\n",
       "         0.        ,  1.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "#cosine_sim[:4, :4]\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a 1-dimensional array with movie titles\n",
    "titles = movies['title']\n",
    "indices = pd.Series(movies.index, index=movies['title'])\n",
    "\n",
    "#TODO: Function that get movie recommendations based on the cosine similarity score of movie genres\n",
    "def genre_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "        \n",
    "    return titles[score_series.index[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and get the top recommendations for a few movies and see how good the recommendations are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12                                         Balto (1995)\n",
       "86                             Dunston Checks In (1996)\n",
       "33                                          Babe (1995)\n",
       "47                                    Pocahontas (1995)\n",
       "51                              Mighty Aphrodite (1995)\n",
       "95                        In the Bleak Midwinter (1995)\n",
       "62    Don't Be a Menace to South Central While Drink...\n",
       "4                    Father of the Bride Part II (1995)\n",
       "64                                      Bio-Dome (1996)\n",
       "68                                        Friday (1995)\n",
       "18                Ace Ventura: When Nature Calls (1995)\n",
       "87                                   Black Sheep (1996)\n",
       "37                                  It Takes Two (1995)\n",
       "7                                   Tom and Huck (1995)\n",
       "1                                        Jumanji (1995)\n",
       "55                       Kids of the Round Table (1995)\n",
       "71                         Kicking and Screaming (1995)\n",
       "74                                     Big Bully (1996)\n",
       "83                   Last Summer in the Hamptons (1995)\n",
       "44                                    To Die For (1995)\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_recommendations('Toy Story (1995)').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Recommendation Model\n",
    "\n",
    "\n",
    "Use the file **ratings.csv** first as it contains User ID, Movie IDs and Ratings. These three elements are all needed for determining the similarity of the users based on their ratings for a particular movie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in user_id and movie_id column with 0\n",
    "ratings['user_id'] = ratings['user_id'].fillna(0)\n",
    "ratings['movie_id'] = ratings['movie_id'].fillna(0)\n",
    "\n",
    "# Replace NaN values in rating column with average of all values\n",
    "ratings['rating'] = ratings['rating'].fillna(ratings['rating'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a random sample of 20,000 ratings (2%) (due to limitation of personal laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 150 entries, 2781 to 1405\n",
      "Data columns (total 3 columns):\n",
      "user_id     150 non-null int64\n",
      "movie_id    150 non-null int64\n",
      "rating      150 non-null int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 4.7 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Randomly sample 1% of the ratings dataset\n",
    "small_data = ratings.sample(frac=0.02)\n",
    "# Check the sample info\n",
    "print(small_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(small_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 3)\n",
      "[[26 63  5]\n",
      " [53 57  3]\n",
      " [ 3 64  4]\n",
      " [66 43  4]]\n"
     ]
    }
   ],
   "source": [
    "# Create two user-item matrices, one for training and another for testing\n",
    "train_data_matrix = train_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])\n",
    "test_data_matrix = test_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])\n",
    "\n",
    "# Check their shape\n",
    "print(train_data_matrix.shape)\n",
    "print(test_data_matrix[:4, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7512, 3)\n",
      "   user_id  movie_id  rating\n",
      "0        1         1       3\n",
      "1        1         3       5\n",
      "2        1         4       4\n",
      "3        1         5       3\n",
      "4        1         6       3\n"
     ]
    }
   ],
   "source": [
    "print(ratings.shape)\n",
    "print(ratings.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.0027764 ,  0.17886317],\n",
       "       [-0.0027764 ,  1.        , -0.21075292],\n",
       "       [ 0.17886317, -0.21075292,  1.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - pairwise_distances(train_data_matrix.T, metric='correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I use the **pairwise_distances** function from sklearn [Pearson Correlation Coefficient](https://stackoverflow.com/questions/1838806/euclidean-distance-vs-pearson-correlation-vs-cosine-similarity). This method provides a safe way to take a distance matrix as input, while preserving compatibility with many other algorithms that take a vector array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.          0.72329023  0.95281888  0.368579  ]\n",
      " [ 0.72329023  1.          0.89877197  0.90851698]\n",
      " [ 0.95281888  0.89877197  1.          0.6333582 ]\n",
      " [ 0.368579    0.90851698  0.6333582   1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# User Similarity Matrix\n",
    "user_correlation = 1 - pairwise_distances(train_data, metric='correlation')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "print(user_correlation[:4, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -0.0027764   0.17886317]\n",
      " [-0.0027764   1.         -0.21075292]\n",
      " [ 0.17886317 -0.21075292  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Item Similarity Matrix\n",
    "item_correlation = 1 - pairwise_distances(train_data_matrix.T, metric='correlation')\n",
    "item_correlation[np.isnan(item_correlation)] = 0\n",
    "print(item_correlation[:4, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.        ,  0.72329023,  0.95281888,  0.368579  ,  0.96847351,\n",
       "        0.9341167 ,  0.9586902 ,  0.86894762, -0.00716502, -0.05882966,\n",
       "        0.55891052,  0.96855523,  0.50213017,  0.99894009,  0.98026905,\n",
       "        0.94036234,  0.98250409,  0.71583578,  0.39991918,  0.85743236,\n",
       "       -0.1719014 ,  0.09629558,  0.32564186,  0.98242496,  0.79054865,\n",
       "        0.96768449,  0.97906829, -0.0445691 ,  0.87582989,  0.41036869,\n",
       "        0.75568298,  0.77795389, -0.05016808,  0.17225581,  0.0055357 ,\n",
       "        0.71490552,  0.97755404,  0.25951408,  0.67789965,  0.99979012,\n",
       "        0.76862471,  0.42081217,  0.99330945,  0.1611823 ,  0.98180887,\n",
       "        0.84715615,  0.99823489,  0.50574087,  0.93831943,  0.96000732,\n",
       "        0.94127972,  0.62877999,  0.97773686,  0.88718325,  0.67250901,\n",
       "        0.92326786,  0.71904396,  0.99927757,  0.46090518, -0.16526317,\n",
       "        0.89615357,  0.79693137,  0.368579  ,  0.96959495,  0.32401391,\n",
       "        0.94400044,  0.98934362,  0.97137818,  0.99173918, -0.06378317,\n",
       "        0.10003458,  0.96307322,  0.19978291,  0.95464973,  0.95100582,\n",
       "        0.98755952,  0.58662875,  0.25602032,  0.9998516 ,  0.78399699,\n",
       "        0.78399699,  0.59163917,  0.81144914,  0.96370386,  0.99867055,\n",
       "        0.50574087,  0.78399699,  0.77162941,  0.54128816,  0.97357309,\n",
       "        0.71805618,  0.91014859,  0.5483349 ,  0.9939506 , -0.05189961,\n",
       "        0.80187519,  0.96534907,  0.63234988, -0.15561247, -0.08896244,\n",
       "        0.21333414,  0.99834571,  0.06386926,  0.81689621, -0.09157712,\n",
       "        0.95586846,  0.2499435 ,  0.97013118,  0.33481717,  0.93365683,\n",
       "        0.98396905,  0.15633292, -0.12587802,  0.95166234, -0.34388135,\n",
       "        0.29091933,  0.89391605,  0.23199911,  0.85721219,  0.9884595 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_correlation[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.0027764 ,  0.17886317],\n",
       "       [-0.0027764 ,  1.        , -0.21075292],\n",
       "       [ 0.17886317, -0.21075292,  1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the similarity matrix in hand, I can now predict the ratings that were not included with the data. Using these predictions, I can then compare them with the test data to attempt to validate the quality of our recommender model.\n",
    "\n",
    "For the user-user CF case, I will look at the similarity between 2 users (A and B, for example) as weights that are multiplied by the ratings of a similar user B (corrected for the average rating of that user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Function to predict ratings\n",
    "def user_mean(user_id):\n",
    "    user_rating = []\n",
    "    for row in ratings:\n",
    "        if row[1] == user_id:\n",
    "            user_rating.append(row[2])\n",
    "    return np.mean(user_rating)\n",
    "\n",
    "def predict(ratings, similarity, type='user'):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    if type == 'user':\n",
    "        for i, rating in enumerate(ratings):\n",
    "            user_id = rating[0]\n",
    "            movie_id = rating[1]\n",
    "            \n",
    "            u_mean = user_mean(user_id)\n",
    "            \n",
    "            pred_rating = u_mean + ( (np.sum(np.dot(similarity[i][i:], np.subtract(rating[rating[i] != user_id][movie_id], user_mean(rating[i]))))) \n",
    "                             / (np.sum(similarity[i][i:])) )\n",
    "            \n",
    "            pred[i] = [user_id, movie_id, pred_rating]\n",
    "#     elif type == 'item':\n",
    "#         for i, ratingin enumerate(ratings):\n",
    "            \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def rmse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    print(pred)\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\WinPython\\python-3.6.5.amd64\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "D:\\Downloads\\WinPython\\python-3.6.5.amd64\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 54 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-00aaf9b9af86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Predict ratings on the training data with both similarity score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0muser_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_correlation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'user'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# item_prediction = predict(train_data_matrix, item_correlation, type='item')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# RMSE on the test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-a6aa2ad6fe4e>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(ratings, similarity, type)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mu_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             pred_rating = u_mean + ( (np.sum(np.dot(similarity[i][similarity[i] != 1], np.subtract(rating[rating[i] != user_id][movie_id], user_mean(rating[i]))))) \n\u001b[0m\u001b[0;32m     19\u001b[0m                              / (np.sum(similarity[i][similarity[i] != 1])) )\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 54 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# Predict ratings on the training data with both similarity score\n",
    "user_prediction = predict(train_data_matrix, user_correlation, type='user')\n",
    "# item_prediction = predict(train_data_matrix, item_correlation, type='item')\n",
    "\n",
    "# RMSE on the test data\n",
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "# print('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
