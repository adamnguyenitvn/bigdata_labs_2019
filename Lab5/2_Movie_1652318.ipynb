{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Let's load this data into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading ratings file\n",
    "# Ignore the timestamp column\n",
    "ratings = pd.read_csv('ratings.csv', encoding='latin-1', usecols=['user_id', 'movie_id', 'rating'])\n",
    "\n",
    "# Reading users file\n",
    "users = pd.read_csv('users.csv', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "\n",
    "# Reading movies file\n",
    "movies = pd.read_csv('movies.csv', encoding='latin-1', usecols=['movie_id', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(100, 3)\n"
    }
   ],
   "source": [
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content-Based Recommendation Model\n",
    "\n",
    "Computes similarity between movies based on movie genres. It will suggest movies that are most similar to a particular movie based on its genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(100, 3)\n"
    }
   ],
   "source": [
    "# Break up the big genre string into a string array\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "print(movies.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movie_id</th>\n      <th>title</th>\n      <th>genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Toy Story (1995)</td>\n      <td>['Animation', \"Children's\", 'Comedy']</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Jumanji (1995)</td>\n      <td>['Adventure', \"Children's\", 'Fantasy']</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Grumpier Old Men (1995)</td>\n      <td>['Comedy', 'Romance']</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Waiting to Exhale (1995)</td>\n      <td>['Comedy', 'Drama']</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Father of the Bride Part II (1995)</td>\n      <td>['Comedy']</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "   movie_id                               title  \\\n0         1                    Toy Story (1995)   \n1         2                      Jumanji (1995)   \n2         3             Grumpier Old Men (1995)   \n3         4            Waiting to Exhale (1995)   \n4         5  Father of the Bride Part II (1995)   \n\n                                   genres  \n0   ['Animation', \"Children's\", 'Comedy']  \n1  ['Adventure', \"Children's\", 'Fantasy']  \n2                   ['Comedy', 'Romance']  \n3                     ['Comedy', 'Drama']  \n4                              ['Comedy']  "
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert genres to string value\n",
    "movies['genres'] = movies['genres'].fillna(\"\").astype('str')\n",
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 44)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(movies['genres'])\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<100x44 sparse matrix of type '<class 'numpy.float64'>'\n\twith 231 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[1.        , 0.15337409, 0.12551391, ..., 0.        , 0.        ,\n        0.        ],\n       [0.15337409, 1.        , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.12551391, 0.        , 1.        , ..., 0.        , 0.        ,\n        0.        ],\n       ...,\n       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n        0.25861841],\n       [0.        , 0.        , 0.        , ..., 0.        , 1.        ,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.25861841, 0.        ,\n        1.        ]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "#cosine_sim[:4, :4]\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a 1-dimensional array with movie titles\n",
    "titles = movies['title']\n",
    "indices = pd.Series(movies.index, index=movies['title'])\n",
    "\n",
    "#TODO: Function that get movie recommendations based on the cosine similarity score of movie genres\n",
    "def genre_recommendations(title):\n",
    "    index = indices[title]\n",
    "    movie_sim_indices = np.argsort(cosine_sim[index])[::-1][1:]\n",
    "    return titles.iloc[movie_sim_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and get the top recommendations for a few movies and see how good the recommendations are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "12                                         Balto (1995)\n86                             Dunston Checks In (1996)\n33                                          Babe (1995)\n47                                    Pocahontas (1995)\n51                              Mighty Aphrodite (1995)\n95                        In the Bleak Midwinter (1995)\n62    Don't Be a Menace to South Central While Drink...\n4                    Father of the Bride Part II (1995)\n64                                      Bio-Dome (1996)\n68                                        Friday (1995)\n18                Ace Ventura: When Nature Calls (1995)\n87                                   Black Sheep (1996)\n37                                  It Takes Two (1995)\n7                                   Tom and Huck (1995)\n1                                        Jumanji (1995)\n55                       Kids of the Round Table (1995)\n71                         Kicking and Screaming (1995)\n74                                     Big Bully (1996)\n83                   Last Summer in the Hamptons (1995)\n44                                    To Die For (1995)\nName: title, dtype: object"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genre_recommendations('Toy Story (1995)').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filtering Recommendation Model\n",
    "\n",
    "\n",
    "Use the file **ratings.csv** first as it contains User ID, Movie IDs and Ratings. These three elements are all needed for determining the similarity of the users based on their ratings for a particular movie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in user_id and movie_id column with 0\n",
    "ratings['user_id'] = ratings['user_id'].fillna(0)\n",
    "ratings['movie_id'] = ratings['movie_id'].fillna(0)\n",
    "\n",
    "# Replace NaN values in rating column with average of all values\n",
    "ratings['rating'] = ratings['rating'].fillna(ratings['rating'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a random sample of 20,000 ratings (2%) (due to limitation of personal laptop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 150 entries, 5639 to 6922\nData columns (total 3 columns):\nuser_id     150 non-null int64\nmovie_id    150 non-null int64\nrating      150 non-null int64\ndtypes: int64(3)\nmemory usage: 4.7 KB\nNone\n"
    }
   ],
   "source": [
    "# Randomly sample 1% of the ratings dataset\n",
    "small_data = ratings.sample(frac=0.02)\n",
    "# Check the sample info\n",
    "print(small_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(small_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(120, 3)\n[[92 72  5]\n [39 56  3]\n [74 58  5]\n [62 25  5]]\n/Users/macbook/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:2: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n  \n/Users/macbook/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n  This is separate from the ipykernel package so we can avoid doing imports until\n"
    }
   ],
   "source": [
    "# Create two user-item matrices, one for training and another for testing\n",
    "train_data_matrix = train_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])\n",
    "test_data_matrix = test_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])\n",
    "\n",
    "# Check their shape\n",
    "print(train_data_matrix.shape)\n",
    "print(test_data_matrix[:4, :4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I use the **pairwise_distances** function from sklearn [Pearson Correlation Coefficient](https://stackoverflow.com/questions/1838806/euclidean-distance-vs-pearson-correlation-vs-cosine-similarity). This method provides a safe way to take a distance matrix as input, while preserving compatibility with many other algorithms that take a vector array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[1.         0.04378945 0.55122386 0.45438699]\n [0.04378945 1.         0.85769485 0.90984727]\n [0.55122386 0.85769485 1.         0.99371818]\n [0.45438699 0.90984727 0.99371818 1.        ]]\n"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# User Similarity Matrix\n",
    "user_correlation = 1 - pairwise_distances(train_data, metric='correlation')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "print(user_correlation[:4, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[[ 1.          0.02800626 -0.20558559]\n [ 0.02800626  1.         -0.02695445]\n [-0.20558559 -0.02695445  1.        ]]\n"
    }
   ],
   "source": [
    "# Item Similarity Matrix\n",
    "item_correlation = 1 - pairwise_distances(train_data_matrix.T, metric='correlation')\n",
    "item_correlation[np.isnan(item_correlation)] = 0\n",
    "print(item_correlation[:4, :4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the similarity matrix in hand, I can now predict the ratings that were not included with the data. Using these predictions, I can then compare them with the test data to attempt to validate the quality of our recommender model.\n",
    "\n",
    "For the user-user CF case, I will look at the similarity between 2 users (A and B, for example) as weights that are multiplied by the ratings of a similar user B (corrected for the average rating of that user)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Function to predict ratings\n",
    "def predict(ratings, similarity, type='user'):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    if type == 'user':\n",
    "        for row, rating in enumerate(ratings):\n",
    "            pred[row] = [rating[0], rating[1], np.sum(np.dot(similarity[row][row:], ratings[:,2][row:])) / np.sum(similarity[row][row:])]\n",
    "    elif type == 'item':\n",
    "        for col, rating in enumerate(ratings.T):\n",
    "            if col == 2:\n",
    "              pred[:, col] = np.sum(np.dot(np.array([similarity[:, col]]).T, np.array([ratings[:, col]])), axis=0)\n",
    "            else:\n",
    "              pred[:, col] = ratings[:, col]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def rmse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    print(pred)\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(pred, actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[33.          5.          3.25871232 49.         91.          3.37297317\n 64.         62.          3.31998719 64.         70.          3.30803062\n 73.         89.          3.30582421 88.         29.          3.2358796\n 25.         62.          3.31917521 91.         90.          3.28201533\n 76.         22.          3.26114078 72.         31.          3.30288105\n 75.         99.          3.34620325 66.         63.          3.31969238\n  6.          3.          3.24881623 40.         35.          3.331037\n 99.         16.          3.32644172 19.         82.          3.40089534\n 10.          1.          3.1800929  42.         90.          3.36977828\n 78.         89.          3.35206269  2.         37.          3.43363741\n  7.         34.          3.36403409 62.         40.          3.3197347\n 14.         73.          3.35553653 56.         33.          3.33201324\n  3.         15.          3.31005139 30.         25.          3.31027913\n 26.         50.          3.29330967 85.         65.          3.30027919\n 81.         48.          3.31483118  8.         20.          3.3397703 ]\nUser-based CF RMSE: 34.91377902182184\n[33.          5.          3.06983986 49.         91.          3.83729983\n 64.         62.          3.83729983 64.         70.          3.06983986\n 73.         89.          3.83729983 88.         29.          2.3023799\n 25.         62.          2.3023799  91.         90.          0.76745997\n 76.         22.          0.76745997 72.         31.          1.53491993\n 75.         99.          3.83729983 66.         63.          1.53491993\n  6.          3.          3.06983986 40.         35.          0.76745997\n 99.         16.          3.06983986 19.         82.          3.83729983\n 10.          1.          3.83729983 42.         90.          2.3023799\n 78.         89.          3.06983986  2.         37.          3.83729983\n  7.         34.          3.06983986 62.         40.          1.53491993\n 14.         73.          3.83729983 56.         33.          3.83729983\n  3.         15.          2.3023799  30.         25.          3.83729983\n 26.         50.          1.53491993 85.         65.          1.53491993\n 81.         48.          2.3023799   8.         20.          3.06983986]\nItem-based CF RMSE: 34.91991943266222\n"
    }
   ],
   "source": [
    "# Predict ratings on the training data with both similarity score\n",
    "user_prediction = predict(train_data_matrix, user_correlation, type='user')\n",
    "item_prediction = predict(train_data_matrix, item_correlation, type='item')\n",
    "\n",
    "# RMSE on the test data\n",
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}